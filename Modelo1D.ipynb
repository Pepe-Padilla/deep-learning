{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pepe-Padilla/deep-learning/blob/main/Modelo1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo1D - DeepLearning\n"
      ],
      "metadata": {
        "id": "anj-GbhgZ_dz"
      },
      "id": "anj-GbhgZ_dz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indice\n",
        "1. Introducción\n",
        "2. Importación y Normalización de datos\n",
        "3. Entrenamiento\n",
        "4. Gráfica de Perdidas\n",
        "5. Test\n",
        "6. Concluciones"
      ],
      "metadata": {
        "id": "ftgA-BvZqssP"
      },
      "id": "ftgA-BvZqssP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1. Introducción"
      ],
      "metadata": {
        "id": "d8MjiSdDsajN"
      },
      "id": "d8MjiSdDsajN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Práctica DL** - Ejercicio de Bootcamp Inteligencia Artificial Full Stack Edición III\n",
        "\n",
        "Este proyecto es un entregable para la práctica del Master Bootcamp Inteligencia Artificial Full Stack Edición III realizado por el centro de formación [@Keepcoding](https://github.com/KeepCoding)\n",
        "\n",
        "---\n",
        "\n",
        "El objetivo de este trabajo consiste en resolver un problema del mundo real empleando para ello técnicas vistas durante las sesiones de dicho módulo. En concreto, se trabajará en predecir la condición médica sufrida por una cohorte de pacientes a partir de las diferentes fuentes de información disponibles (imágenes y datos tabulares).\n",
        "\n",
        "Las imagenes deben entrenar y obtener una de los siguientes respuestas:\n",
        "\n",
        "| Enfermedad | Descripción | Código | Indice en salida |\n",
        "|------------|-------------|--------|------------------|\n",
        "| Actinic keratoses y carcinoma de células escamosas | Tipo de cáncer de piel | akiec | 0 |\n",
        "| Nevus melanocítico | Lesión benigna común | nv | 1 |\n",
        "| Melanoma | Tipo de cáncer de piel agresivo | mel | 2 |\n",
        "| Lesiones benignas de queratosis | Incluyen lentigo solar y queratosis seborreica | bkl | 3 |\n",
        "| Dermatofibroma | Lesión benigna del tejido fibroso | df | 4 |\n",
        "| Vasculares | Lesiones vasculares como hemangiomas | vasc | 5 |\n",
        "| Lesión de células basales | Un tipo de cáncer de piel menos agresivo que el melanoma | bcc | 6 |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zcRHZ_Gzm4ax"
      },
      "id": "zcRHZ_Gzm4ax"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Importación y Normalización de datos"
      ],
      "metadata": {
        "id": "h-EVoxAar8z5"
      },
      "id": "h-EVoxAar8z5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos el dataset que vamos a utilizar: el MNIST\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Cargamos el dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15)\n",
        "\n",
        "# Normalizamos el dataset\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "x_val= x_val / 255.\n",
        "\n",
        "# El dataset ya está dividido en train, validation y test. Dentro de cada uno\n",
        "# de estos subsets ver el número de ejemplos y las dimensiones:\n",
        "print(\"El conjunto de entrenamiento tiene dimensiones: \", x_train.shape)\n",
        "print(\"El conjunto de validación tiene dimensiones: \",x_val.shape)\n",
        "print(\"El conjunto de test tiene dimensiones: \",x_test.shape)\n",
        "\n",
        "#Hacemos lo mismo para las etiquetas.\n",
        "print(\"El conjunto de entrenamiento (etiquetas) tiene dimensiones: \", y_train.shape)\n",
        "print(\"El conjunto de validación (etiquetas) tiene dimensiones: \",y_val.shape)\n",
        "print(\"El conjunto de test (etiquetas) tiene dimensiones: \",y_test.shape)\n",
        "\n",
        "# Cada etiqueta debería ser guardada en un vector de longitud = N_CLASES, con todo 0s excepto para\n",
        "# el índice que indica la clase a la que pertenece la imágen, que contiene un 1)\n",
        "# Por ejemplo, si tenemos 10 clases (números del 0 al 9), y la etiqueta\n",
        "# pertenece al número 5:\n",
        "# label = [0 0 0 0 0 1 0 0 0 0]\n",
        "#Esto se llama one-hot encodding, cambiamos el formato de la etiquetas\n",
        "y_train = tf.one_hot(y_train, depth=10)\n",
        "y_val = tf.one_hot(y_val, depth=10)\n",
        "y_test = tf.one_hot(y_test, depth=10)\n",
        "\n",
        "print(\"El conjunto de entrenamiento (etiquetas) en one-hot encoding tiene dimensiones: \", y_train.shape)\n",
        "print(\"El conjunto de validación (etiquetas) en one-hot encoding tiene dimensiones: \",y_val.shape)\n",
        "print(\"El conjunto de test (etiquetas) en one-hot encoding tiene dimensiones: \",y_test.shape)\n",
        "\n",
        "# Veamos algunas de las imágenes del dataset...\n",
        "# Para ello, solo necesitamos acceder a un vector de nuestra matrix y\n",
        "# redimensionarlo a 28x28\n",
        "plt.subplot(131)\n",
        "plt.imshow(np.reshape(x_train[0, :], (28, 28)), cmap='gray')\n",
        "plt.subplot(132)\n",
        "plt.imshow(np.reshape(x_train[27500, :], (28, 28)), cmap='gray')\n",
        "plt.subplot(133)\n",
        "plt.imshow(np.reshape(x_train[41000, :], (28, 28)), cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "9enRemE_m01j",
        "outputId": "894411af-f2e0-4d9d-ebd1-4d819a497841"
      },
      "id": "9enRemE_m01j",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de entrenamiento tiene dimensiones:  (51000, 28, 28)\n",
            "El conjunto de validación tiene dimensiones:  (9000, 28, 28)\n",
            "El conjunto de test tiene dimensiones:  (10000, 28, 28)\n",
            "El conjunto de entrenamiento (etiquetas) tiene dimensiones:  (51000,)\n",
            "El conjunto de validación (etiquetas) tiene dimensiones:  (9000,)\n",
            "El conjunto de test (etiquetas) tiene dimensiones:  (10000,)\n",
            "El conjunto de entrenamiento (etiquetas) en one-hot encoding tiene dimensiones:  (51000, 10)\n",
            "El conjunto de validación (etiquetas) en one-hot encoding tiene dimensiones:  (9000, 10)\n",
            "El conjunto de test (etiquetas) en one-hot encoding tiene dimensiones:  (10000, 10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e02bc7b1550>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ya hemos visto un poco en qué consiste el dataset del MNIST.\n",
        "# Reducimos tamaño de entrenamiento para que vaya más rápido\n",
        "size_train=10000\n",
        "x_train=x_train[0:size_train]\n",
        "y_train= y_train[0:size_train]\n",
        "# Convertimos las imágenes a vectores, dado que aún no hemos visto cómo podemos implementar un modelo que trabaje con imágenes\n",
        "x_train = tf.reshape(x_train, shape=(size_train, -1)) # Nuestros datos ya están en formato [N_instancias, variables] (nº instancias, 784 (28+28) pixels).\n",
        "x_val = tf.reshape(x_val, shape=(9000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] ((nº instancias, 784 (28+28) pixels).\n",
        "x_test = tf.reshape(x_test, shape=(10000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] ((nº instancias, 784 (28+28) pixels)."
      ],
      "metadata": {
        "id": "QSA7Eo02t4-Q"
      },
      "id": "QSA7Eo02t4-Q",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.dtype)\n",
        "print(x_test.dtype)\n",
        "print(y_train.dtype)\n",
        "print(y_test.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUoVWcD7t84H",
        "outputId": "0d0c9615-b402-4c30-b305-cded553ff9df"
      },
      "id": "oUoVWcD7t84H",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<dtype: 'float64'>\n",
            "<dtype: 'float64'>\n",
            "<dtype: 'float32'>\n",
            "<dtype: 'float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convertimos las etiquetas a float64\n",
        "y_train = tf.cast(y_train, \"float64\")\n",
        "y_test = tf.cast(y_test, \"float64\")"
      ],
      "metadata": {
        "id": "HFnX9bTguBs4"
      },
      "id": "HFnX9bTguBs4",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.dtype)\n",
        "print(x_test.dtype)\n",
        "print(y_train.dtype)\n",
        "print(y_test.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcNt49HQuDRQ",
        "outputId": "16ad55cb-e0d7-4326-bd34-0d83e03b3999"
      },
      "id": "kcNt49HQuDRQ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<dtype: 'float64'>\n",
            "<dtype: 'float64'>\n",
            "<dtype: 'float64'>\n",
            "<dtype: 'float64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Entrenamiento"
      ],
      "metadata": {
        "id": "gXK94dEvtl9Y"
      },
      "id": "gXK94dEvtl9Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# hiperparametros\n",
        "\n",
        "learning_rate = 0.1\n",
        "n_epochs = 30\n",
        "batch_size = 100"
      ],
      "metadata": {
        "id": "hwueuMWQtk5Z"
      },
      "id": "hwueuMWQtk5Z",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Definimos el batch de entrenamiento\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_ds = train_ds.shuffle(10000).batch(batch_size)"
      ],
      "metadata": {
        "id": "3MBi3_9BuN_i"
      },
      "id": "3MBi3_9BuN_i",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED0WNPxU_BU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e37c00-6b7b-4e8c-da51-9e6be5d1f16d"
      },
      "source": [
        "# cuantas iteraciones habrá por época?\n",
        "# en una época se tienen que ver todos los elementos del dataset, y estamos\n",
        "# pasándole los elementos de 100 en 100, así que habrá 60000 / 100 = 600 épocas\n",
        "total_batch =  x_train.shape[0] // batch_size\n",
        "print(total_batch)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ],
      "id": "ED0WNPxU_BU1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOUtLtXg4ThZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "5a4e7b31-6ed4-4b2b-af39-b19a77e38255"
      },
      "source": [
        "# y creamos las variables W y b para el entrenamiento\n",
        "W = tf.zeros([784, 10], tf.double)\n",
        "b = tf.ones([10], tf.double)\n",
        "\n",
        "# para almacenar el histórico de costes\n",
        "costs = []\n",
        "\n",
        "# Create a TensorFlow session\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# entrenamiento de nuestra red\n",
        "for epoch in range(n_epochs):\n",
        "    avg_cost = 0.\n",
        "\n",
        "    # y si en vez de actualizar los pesos para cada imagen, lo hacemos\n",
        "    # de X en X imágenes?\n",
        "    # Get an iterator for the dataset\n",
        "    iterator = train_ds.make_initializable_iterator()\n",
        "    next_element = iterator.get_next()\n",
        "    sess.run(iterator.initializer)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            batch_xs, batch_ys = sess.run(next_element)\n",
        "\n",
        "            # empezamos con la optimización\n",
        "\n",
        "            # haremos uso de tf.GradientTape, que lleva un control de las variables\n",
        "            # para poder calcular sus gradientes\n",
        "\n",
        "            # Since we are not using eager execution, we don't need GradientTape\n",
        "            # Operations are added to the computational graph.\n",
        "            pred = tf.nn.softmax(tf.matmul(batch_xs, W) + b)\n",
        "            cost = tf.reduce_mean(-tf.reduce_sum(batch_ys*tf.math.log(pred), axis=1))\n",
        "\n",
        "            # Define optimization step using an optimizer\n",
        "            optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "            train_op = optimizer.minimize(cost)\n",
        "\n",
        "            # Execute the training operation within the session\n",
        "            _, c = sess.run([train_op, cost])\n",
        "            avg_cost += c / total_batch\n",
        "\n",
        "        except tf.errors.OutOfRangeError:\n",
        "            break\n",
        "\n",
        "    # guardamos nuestro coste en el histórico\n",
        "    costs.append(avg_cost)\n",
        "\n",
        "    # imprimimos las iteraciones\n",
        "    print(\"[{}] cost: {}\".format(epoch, avg_cost))\n",
        "\n",
        "print(\"Entrenamiento finalizado!!\")\n",
        "# Close the session when done.\n",
        "sess.close()\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-24-287d292b0077>:19: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_initializable_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No variables to optimize.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-287d292b0077>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# Define optimization step using an optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# Execute the training operation within the session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \"\"\"\n\u001b[0;32m--> 495\u001b[0;31m     grads_and_vars = self.compute_gradients(\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0mprocessors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No variables to optimize.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m     \u001b[0mvar_refs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     grads = gradients.gradients(\n",
            "\u001b[0;31mValueError\u001b[0m: No variables to optimize."
          ]
        }
      ],
      "id": "WOUtLtXg4ThZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Gráfica de Perdidas"
      ],
      "metadata": {
        "id": "wbLD9i9pKwLc"
      },
      "id": "wbLD9i9pKwLc"
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos nuestra función de pérdidas con respecto a las épocas ejecutadas\n",
        "plt.plot(np.arange(0, n_epochs), costs)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qDEI_KuxKXZR"
      },
      "id": "qDEI_KuxKXZR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Test"
      ],
      "metadata": {
        "id": "oMEjoWaCK4f1"
      },
      "id": "oMEjoWaCK4f1"
    },
    {
      "cell_type": "code",
      "source": [
        "# comprobamos lo que ha aprendido nuestra red\n",
        "pred = tf.nn.softmax(tf.matmul(x_test, W) + b)\n",
        "correct_prediction =   tf.equal(tf.argmax(pred, 1), tf.argmax(y_test, 1))\n",
        "\n",
        "# calculamos el accuracy (precisión)\n",
        "accuracy =  tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(\"Accuracy:\", accuracy.numpy())"
      ],
      "metadata": {
        "id": "vGZDHml_vPox"
      },
      "id": "vGZDHml_vPox",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Concluciones"
      ],
      "metadata": {
        "id": "m3DusFPhK8tX"
      },
      "id": "m3DusFPhK8tX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí van mis concluciones"
      ],
      "metadata": {
        "id": "s-kPUhIOLCie"
      },
      "id": "s-kPUhIOLCie"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}