{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pepe-Padilla/deep-learning/blob/main/Modelo1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo1D - DeepLearning\n"
      ],
      "metadata": {
        "id": "anj-GbhgZ_dz"
      },
      "id": "anj-GbhgZ_dz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indice\n",
        "1. Introducción\n",
        "2. Importación y Normalización de datos\n",
        "3. Entrenamiento\n",
        "4. Gráfica de Perdidas\n",
        "5. Test\n",
        "6. Concluciones"
      ],
      "metadata": {
        "id": "ftgA-BvZqssP"
      },
      "id": "ftgA-BvZqssP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1. Introducción"
      ],
      "metadata": {
        "id": "d8MjiSdDsajN"
      },
      "id": "d8MjiSdDsajN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Práctica DL** - Ejercicio de Bootcamp Inteligencia Artificial Full Stack Edición III\n",
        "\n",
        "Este proyecto es un entregable para la práctica del Master Bootcamp Inteligencia Artificial Full Stack Edición III realizado por el centro de formación [@Keepcoding](https://github.com/KeepCoding)\n",
        "\n",
        "---\n",
        "\n",
        "El objetivo de este trabajo consiste en resolver un problema del mundo real empleando para ello técnicas vistas durante las sesiones de dicho módulo. En concreto, se trabajará en predecir la condición médica sufrida por una cohorte de pacientes a partir de las diferentes fuentes de información disponibles (imágenes y datos tabulares).\n",
        "\n",
        "Las imagenes deben entrenar y obtener una de los siguientes respuestas:\n",
        "\n",
        "| Enfermedad | Descripción | Código | Indice en salida |\n",
        "|------------|-------------|--------|------------------|\n",
        "| Actinic keratoses y carcinoma de células escamosas | Tipo de cáncer de piel | akiec | 0 |\n",
        "| Nevus melanocítico | Lesión benigna común | nv | 1 |\n",
        "| Melanoma | Tipo de cáncer de piel agresivo | mel | 2 |\n",
        "| Lesiones benignas de queratosis | Incluyen lentigo solar y queratosis seborreica | bkl | 3 |\n",
        "| Dermatofibroma | Lesión benigna del tejido fibroso | df | 4 |\n",
        "| Vasculares | Lesiones vasculares como hemangiomas | vasc | 5 |\n",
        "| Lesión de células basales | Un tipo de cáncer de piel menos agresivo que el melanoma | bcc | 6 |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zcRHZ_Gzm4ax"
      },
      "id": "zcRHZ_Gzm4ax"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Importación y Normalización de datos"
      ],
      "metadata": {
        "id": "h-EVoxAar8z5"
      },
      "id": "h-EVoxAar8z5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Imports"
      ],
      "metadata": {
        "id": "Bqi5lUEco_x3"
      },
      "id": "Bqi5lUEco_x3"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Primero las importaciones que necesitaremos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "floJBQKoo9Yi"
      },
      "id": "floJBQKoo9Yi",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Obtención de datos"
      ],
      "metadata": {
        "id": "c9fbl52MpHYT"
      },
      "id": "c9fbl52MpHYT"
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Obtención de datos\n",
        "df = pd.read_csv(\"/content/HAM10000_metadata.csv\", sep=\",\")\n"
      ],
      "metadata": {
        "id": "9enRemE_m01j"
      },
      "id": "9enRemE_m01j",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Inspección de elementos"
      ],
      "metadata": {
        "id": "SzVwVBfrpR7o"
      },
      "id": "SzVwVBfrpR7o"
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Inspeccionamos y normalización\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "\n",
        "# Primero busquemos nulls en las columnas que valgan la pena\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Solo age tiene null, solo se me ocurre rellenar con la mediana\n",
        "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
        "df['age'] = df['age'] / 100  # Escalamos considerando 100 como el máximo teórico\n",
        "\n",
        "# para evitar problemas después, convertir el tipo de age a un float compatible para Tensor\n",
        "df['age'] = df['age'].astype(np.float32)\n",
        "\n",
        "# Convertimos las variables 'sex' y 'localization' a categorías one-hot encoding\n",
        "df = pd.get_dummies(df, columns=['sex', 'localization'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hALkPFF8prrN",
        "outputId": "2d5d85ea-ffb8-4aec-eb1b-9202226ebb8f"
      },
      "id": "hALkPFF8prrN",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     lesion_id      image_id   dx dx_type   age   sex localization\n",
            "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
            "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
            "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
            "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
            "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10015 entries, 0 to 10014\n",
            "Data columns (total 7 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   lesion_id     10015 non-null  object \n",
            " 1   image_id      10015 non-null  object \n",
            " 2   dx            10015 non-null  object \n",
            " 3   dx_type       10015 non-null  object \n",
            " 4   age           9958 non-null   float64\n",
            " 5   sex           10015 non-null  object \n",
            " 6   localization  10015 non-null  object \n",
            "dtypes: float64(1), object(6)\n",
            "memory usage: 547.8+ KB\n",
            "None\n",
            "               age\n",
            "count  9958.000000\n",
            "mean     51.863828\n",
            "std      16.968614\n",
            "min       0.000000\n",
            "25%      40.000000\n",
            "50%      50.000000\n",
            "75%      65.000000\n",
            "max      85.000000\n",
            "lesion_id        0\n",
            "image_id         0\n",
            "dx               0\n",
            "dx_type          0\n",
            "age             57\n",
            "sex              0\n",
            "localization     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Separación de datos"
      ],
      "metadata": {
        "id": "ZkmboPe6pWlo"
      },
      "id": "ZkmboPe6pWlo"
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Separamos datos\n",
        "x = df.drop(['lesion_id', 'image_id', 'dx', 'dx_type'], axis=1)\n",
        "y = pd.get_dummies(df['dx'], columns=['dx'])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True, test_size=0.20)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, shuffle=True, test_size=0.15)"
      ],
      "metadata": {
        "id": "z737HyMBpmo9"
      },
      "id": "z737HyMBpmo9",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Verificación"
      ],
      "metadata": {
        "id": "PoOBF3YVpcyQ"
      },
      "id": "PoOBF3YVpcyQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Verificación de normalización\n",
        "print(x_train.info())\n",
        "print(y_train.info())\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1TMx0o-p3Wb",
        "outputId": "ed56fddf-8f96-4bbf-a742-3c7c41ca4b00"
      },
      "id": "D1TMx0o-p3Wb",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 6810 entries, 1508 to 3452\n",
            "Data columns (total 19 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   age                           6810 non-null   float32\n",
            " 1   sex_female                    6810 non-null   bool   \n",
            " 2   sex_male                      6810 non-null   bool   \n",
            " 3   sex_unknown                   6810 non-null   bool   \n",
            " 4   localization_abdomen          6810 non-null   bool   \n",
            " 5   localization_acral            6810 non-null   bool   \n",
            " 6   localization_back             6810 non-null   bool   \n",
            " 7   localization_chest            6810 non-null   bool   \n",
            " 8   localization_ear              6810 non-null   bool   \n",
            " 9   localization_face             6810 non-null   bool   \n",
            " 10  localization_foot             6810 non-null   bool   \n",
            " 11  localization_genital          6810 non-null   bool   \n",
            " 12  localization_hand             6810 non-null   bool   \n",
            " 13  localization_lower extremity  6810 non-null   bool   \n",
            " 14  localization_neck             6810 non-null   bool   \n",
            " 15  localization_scalp            6810 non-null   bool   \n",
            " 16  localization_trunk            6810 non-null   bool   \n",
            " 17  localization_unknown          6810 non-null   bool   \n",
            " 18  localization_upper extremity  6810 non-null   bool   \n",
            "dtypes: bool(18), float32(1)\n",
            "memory usage: 199.5 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 6810 entries, 1508 to 3452\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   akiec   6810 non-null   bool \n",
            " 1   bcc     6810 non-null   bool \n",
            " 2   bkl     6810 non-null   bool \n",
            " 3   df      6810 non-null   bool \n",
            " 4   mel     6810 non-null   bool \n",
            " 5   nv      6810 non-null   bool \n",
            " 6   vasc    6810 non-null   bool \n",
            "dtypes: bool(7)\n",
            "memory usage: 99.8 KB\n",
            "None\n",
            "(6810, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Entrenamiento"
      ],
      "metadata": {
        "id": "gXK94dEvtl9Y"
      },
      "id": "gXK94dEvtl9Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports necesarios\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hiper-parámetros de nuestra red\n",
        "lr = 0.005\n",
        "n_epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "# Implementamos la red empleando Keras\n",
        "model = Sequential() # Instancia de modelo API secuencial\n",
        "model.add(Flatten()) # Estiramos los datos en forma de vector como entrada a nuestro Perceptrón Simple\n",
        "model.add(Dense(10, input_shape=(19,), activation=\"softmax\")) # Construimos nuestro Perceptrón simple con una única capa Dense\n",
        "\n",
        "# Compilamos y entrenamos el modelo SGD\n",
        "print(\"[INFO]: Entrenando red neuronal...\")\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr), metrics=[\"accuracy\"])\n",
        "H = model.fit(x_train.values, y_train, validation_data=(x_val.values, y_val), epochs=n_epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluando el modelo de predicción\n",
        "print(\"[INFO]: Evaluando red neuronal...\")\n",
        "predictions = model.predict(x_test, batch_size=batch_size)\n",
        "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "trVJjWzMOHZ6",
        "outputId": "1cc017c5-3305-447e-956a-55434aa25517"
      },
      "id": "trVJjWzMOHZ6",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Entrenando red neuronal...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid dtype: object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5452e2338f62>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO]: Entrenando red neuronal...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Evaluando el modelo de predicción\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid dtype: object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Gráfica de Perdidas"
      ],
      "metadata": {
        "id": "wbLD9i9pKwLc"
      },
      "id": "wbLD9i9pKwLc"
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos nuestra función de pérdidas con respecto a las épocas ejecutadas\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "qDEI_KuxKXZR"
      },
      "id": "qDEI_KuxKXZR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Test"
      ],
      "metadata": {
        "id": "oMEjoWaCK4f1"
      },
      "id": "oMEjoWaCK4f1"
    },
    {
      "cell_type": "code",
      "source": [
        "# comprobamos lo que ha aprendido nuestra red\n",
        "pred = tf.nn.softmax(tf.matmul(x_test, W) + b)\n",
        "correct_prediction =   tf.equal(tf.argmax(pred, 1), tf.argmax(y_test, 1))\n",
        "\n",
        "# calculamos el accuracy (precisión)\n",
        "accuracy =  tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(\"Accuracy:\", accuracy.numpy())"
      ],
      "metadata": {
        "id": "vGZDHml_vPox"
      },
      "id": "vGZDHml_vPox",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Concluciones"
      ],
      "metadata": {
        "id": "m3DusFPhK8tX"
      },
      "id": "m3DusFPhK8tX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí van mis concluciones"
      ],
      "metadata": {
        "id": "s-kPUhIOLCie"
      },
      "id": "s-kPUhIOLCie"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}